{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urllib\n",
    "\n",
    "A standard Python 3 library for web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "html = urlopen(\"http://pythonscraping.com/pages/page1.html\")\n",
    "# print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup\n",
    "\n",
    "A Python library for Web Scraping. The library creates 4 objects. Beautiful Soup objects which are the DOM similar objects. Tag objects which are lists or returned indiviudally by calling find and findAll on a bsObject, or drilling down. Navigable Strings objects which are used to represent text within tags, rather than tags themselves. Comment objects, which help find HTML coments <!-- -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Collecting package metadata (current_done\n\bdone\n\n## Package Plan ##\n\n  environment location: /Users/asisasotelo/opt/anaconda3/envs/pyml\n\n  added / updated specs:\n    - anaconda\n    - beautifulsoup4\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    beautifulsoup4-4.9.1       |           py37_0         172 KB\n    ------------------------------------------------------------\n                                           Total:         172 KB\n\nThe following packages will be UPDATED:\n\n  beautifulsoup4                               4.8.2-py37_0 --> 4.9.1-py37_0\n\n\n\nDownloading and Extracting Packages\nbeautifulsoup4-4.9.1 | 172 KB    | ##################################### | 100% \nPreparing transaction:done\nVerifying transaction:done\nExecuting transaction:done\n"
    }
   ],
   "source": [
    "#!conda install -y anaconda beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "None\n"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "bsObj = BeautifulSoup(html.read()) # Creates a DOM like object\n",
    "print(bsObj.h1) # The h1 is similar to a //element xpath query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Title BS4 HTTP/Attribute Err Code Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError # HTTP error can be a 404 not found or 500 internal server err\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html=urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(html.read())\n",
    "        title =bsObj.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title = getTitle(\"http://www.pythonscraping.com/exercises/exercise1.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "An Interesting Title\n"
    }
   ],
   "source": [
    "print(title.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FindAll Functions\n",
    "\n",
    "This bsObj.findALL takes 6 arguments findAll(tag,attributes,recursive,text,limit,keywords)\n",
    "\n",
    "The bsObj.find(tag, atttributes,recursive, text, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[<span class=\"green\">Anna\nPavlovna Scherer</span>, <span class=\"green\">Empress Marya\nFedorovna</span>, <span class=\"green\">Prince Vasili Kuragin</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">St. Petersburg</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the prince</span>, <span class=\"green\">the prince</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Prince Vasili</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Wintzingerode</span>, <span class=\"green\">King of Prussia</span>, <span class=\"green\">le Vicomte de Mortemart</span>, <span class=\"green\">Montmorencys</span>, <span class=\"green\">Rohans</span>, <span class=\"green\">Abbe Morio</span>, <span class=\"green\">the Emperor</span>, <span class=\"green\">the prince</span>, <span class=\"green\">Prince Vasili</span>, <span class=\"green\">Dowager Empress Marya Fedorovna</span>, <span class=\"green\">the baron</span>, <span class=\"green\">Anna Pavlovna</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">Anna Pavlovna's</span>, <span class=\"green\">Her Majesty</span>, <span class=\"green\">Baron\nFunke</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anna\nPavlovna</span>, <span class=\"green\">the Empress</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anatole</span>, <span class=\"green\">the prince</span>, <span class=\"green\">The prince</span>, <span class=\"green\">Anna\nPavlovna</span>, <span class=\"green\">Anna Pavlovna</span>]\n"
    }
   ],
   "source": [
    "html = urlopen(\"http://www.pythonscraping.com/pages/warandpeace.html\")\n",
    "bsObj = BeautifulSoup(html)\n",
    "print(bsObj.findAll(\"span\", {\"class\":\"green\"})) # Two Args tagName, tagAttributes\n",
    "\n",
    "\n",
    "# To more than one attribut\n",
    "\n",
    "bsObj.findAll(\"span\",{\"class\":\"green\",\"class\":\"red\"})\n",
    "\n",
    "# Recursion argument is Boolean if set to true it will look into children\n",
    "\n",
    "# Text argument matches based on the text content of the tags (text=\"the prince\")\n",
    "\n",
    "# Limit is only used in the findAll, this only returns the first x items.abs\n",
    "\n",
    "# The keyword argument allows you to select tags that contain a particular attribhute this addas an and functionality to attribute search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating Trees\n",
    "\n",
    "The findAll function is responsible for finding tags based on their name and attribute. But what if you need to find a tag based on its location in a document? Thatâ€™s where tree navigation comes in handy.\n",
    "\n",
    "Children and Descendants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<th>\nItem Title\n</th>\n<th>\nDescription\n</th>\n<th>\nCost\n</th>\n<th>\nImage\n</th>\n"
    }
   ],
   "source": [
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj = BeautifulSoup(html)\n",
    "for child in bsObj.find(\"table\",{\"id\":\"giftList\"}).tr.children:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n<tr class=\"gift\" id=\"gift1\"><td>\nVegetable Basket\n</td><td>\nThis vegetable basket is the perfect gift for your health conscious (or overweight) friends!\n<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>\n</td><td>\n$15.00\n</td><td>\n<img src=\"../img/gifts/img1.jpg\"/>\n</td></tr>\n\n\n<tr class=\"gift\" id=\"gift2\"><td>\nRussian Nesting Dolls\n</td><td>\nHand-painted by trained monkeys, these exquisite dolls are priceless! And by \"priceless,\" we mean \"extremely expensive\"! <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>\n</td><td>\n$10,000.52\n</td><td>\n<img src=\"../img/gifts/img2.jpg\"/>\n</td></tr>\n\n\n<tr class=\"gift\" id=\"gift3\"><td>\nFish Painting\n</td><td>\nIf something seems fishy about this painting, it's because it's a fish! <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>\n</td><td>\n$10,005.00\n</td><td>\n<img src=\"../img/gifts/img3.jpg\"/>\n</td></tr>\n\n\n<tr class=\"gift\" id=\"gift4\"><td>\nDead Parrot\n</td><td>\nThis is an ex-parrot! <span class=\"excitingNote\">Or maybe he's only resting?</span>\n</td><td>\n$0.50\n</td><td>\n<img src=\"../img/gifts/img4.jpg\"/>\n</td></tr>\n\n\n<tr class=\"gift\" id=\"gift5\"><td>\nMystery Box\n</td><td>\nIf you love suprises, this mystery box is for you! Do not place on light-colored surfaces. May cause oil staining. <span class=\"excitingNote\">Keep your friends guessing!</span>\n</td><td>\n$1.50\n</td><td>\n<img src=\"../img/gifts/img6.jpg\"/>\n</td></tr>\n\n\n"
    }
   ],
   "source": [
    "# The Sibling Function finds all siblings of the tag on the same level making it easy to find print out all of the title rows\n",
    "\n",
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj = BeautifulSoup(html)\n",
    "\n",
    "for sibling in bsObj.find(\"table\", {\"id\":\"giftList\"}).tr.next_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex\n",
    "\n",
    "\"Say you have a problem, now say you want to solve it with Regex, well now you have two problems\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to identify emails with Regex\n",
    "\n",
    "Rule 1.\n",
    "    First part of the email contains at least one of the following: uppercase letters, lower \n",
    "    case letters, the numbers 0-9 periods(.) plus signs or underscores.\n",
    "\n",
    "    [A-Z a-z 0-9\\._+]+\n",
    "\n",
    "Rule 2.\n",
    "    After this the email address contains the symbol @\n",
    "    @\n",
    "Rule 3. The email address must then contain one uppercase or lowercase letters\n",
    "    [A-z a-z]+\n",
    "\n",
    "Rule 4\n",
    "    This is followed by a period \\.\n",
    "\n",
    "Rule 5 \n",
    "    Finally the email ends with com edu org or net\n",
    "    (com|edu|org|net)\n",
    "\n",
    "REGEX FOR EMAILS [A-Za-z0-9\\._+]+@[A-Za-z]+\\.(com|org|edu|net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex and Beautiful Soup\n",
    "\n",
    "Say we want to get all the images of a page in a section. We look for a similar pattern in their path. In the instance of our sample web page it is \\.\\.\\/img\\/gifts/img.*\\.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../img/gifts/img1.jpg\n../img/gifts/img2.jpg\n../img/gifts/img3.jpg\n../img/gifts/img4.jpg\n../img/gifts/img6.jpg\n"
    }
   ],
   "source": [
    "html = urlopen(\"http://www.pythonscraping.com/pages/page3.html\")\n",
    "bsObj=BeautifulSoup(html)\n",
    "images = bsObj.findAll(\"img\", {\"src\":re.compile(\"\\.\\.\\/img\\/gifts\\/img.*\\.jpg\")})\n",
    "\n",
    "for image in images:\n",
    "    print(image[\"src\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A python list of attirbutes can be automatically accessed by calling myTags.attrs, this returns a dictionary object which makes retrieval and manipulation of these attributes trivial. The source location, for example, can be found using the following line\n",
    "\n",
    "#myTag.attrs['src']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Expressions\n",
    "\n",
    "BS4 allows us to pass certain types of functions as parameters into the findAll function. The only restriction is that these funcitons must take a tag object as an argument andreturn a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Example\n",
    "soup.findAll(lambda tag: len(tag.attrs)==2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Better Scraping\n",
    "\n",
    "*  Look for a \"print this page\" link\n",
    "*  Look for info hidden in JS file.Might need to examine imported JS files\n",
    "*  Maybe other websites have the information you are looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitpymlcondabc618996cd0c43dfa1103b5dea3f9081",
   "display_name": "Python 3.7.6 64-bit ('pyml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}